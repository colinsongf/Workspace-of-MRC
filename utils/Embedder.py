#!/usr/bin/python3# -*- coding: utf-8 -*-# @Time    : 2019-07-09 21:33# @Author  : apollo2mars# @File    : Embedding.py# @Contact : apollo2mars@gmail.com# @Desc    :import pickle, osimport numpy as npdef _load_word_vec(path, word2idx=None):    fin = open(path, 'r', encoding='utf-8', newline='\n', errors='ignore')    word_vec = {}    for line in fin:        tokens = line.rstrip().split(' ')        if word2idx is None or tokens[0] in word2idx.keys():            print(tokens[0])            print(tokens[1:])            word_vec[tokens[0]] = np.asarray(tokens[1:], dtype='float32')    return word_vecdef build_embedding_matrix(word2idx, embed_dim, dat_fname):    if os.path.exists(dat_fname):        print('loading embedding_matrix:', dat_fname)        embedding_matrix = pickle.load(open(dat_fname, 'rb'))    else:        print('loading word vectors...')        embedding_matrix = np.zeros((len(word2idx) + 2, embed_dim))  # idx 0 and len(word2idx)+1 are all-zeros        fname = '/export/home/sunhongchao1/1-NLU/Workspace-of-NLU/resources/Tencent_AILab_ChineseEmbedding.txt'        word_vec = _load_word_vec(fname, word2idx=word2idx)        print('building embedding_matrix:', dat_fname)        for word, i in word2idx.items():                embedding_matrix[i] = word_vec[word]        pickle.dump(embedding_matrix, open(dat_fname, 'wb'))    #else:    #    print('loading word vectors...')    #    embedding_matrix = np.zeros((len(word2idx) + 2, embed_dim))  # idx 0 and len(word2idx)+1 are all-zeros    #    #embedding_matrix = np.zeros((len(word2idx) + 2, embed_dim))  # idx 0 and len(word2idx)+1 are all-zeros    #    fname = './glove.twitter.27B/glove.twitter.27B.' + str(embed_dim) + 'd.txt' \    #        if embed_dim != 300 else '/export/home/sunhongchao1/1-NLU/Workspace-of-NLU/resources/glove.42B.300d.txt'    #    word_vec = _load_word_vec(fname, word2idx=word2idx)    #    print('building embedding_matrix:', dat_fname)    #    for word, i in word2idx.items():    #        vec = word_vec.get(word)    #        if vec is not None:    #            # words not found in embedding index will be all-zeros.    #            embedding_matrix[i] = vec    #    pickle.dump(embedding_matrix, open(dat_fname, 'wb'))    return embedding_matrix